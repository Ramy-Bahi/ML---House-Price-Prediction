# ML-House-Price-Prediction
Machine Learning project comparing Linear and Polynomial Regression on housing data.

---

# ğŸ  House Prices Prediction â€” Linear & Polynomial Regression

This project explores **Machine Learning regression techniques** on the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) dataset from Kaggle.  
Itâ€™s part of my journey to fully master **Machine Learning** before moving into **Deep Learning**.

---

## ğŸ“˜ Project Overview

The goal is to predict the **Sale Price** of residential homes based on multiple numerical and categorical features.

This project is divided into two separate notebooks:

| Notebook | Description |
|-----------|--------------|
| ğŸ““ `linear_regression.ipynb` | Builds a clean linear regression pipeline with full preprocessing, encoding, scaling, and evaluation. |
| ğŸ““ `polynomial_regression.ipynb` | Extends the linear model using polynomial features (degree = 2) to explore non-linear relationships. |

---

## âš™ï¸ Technologies Used

- **Python 3.x**
- **NumPy**, **Pandas** â†’ data manipulation  
- **Matplotlib**, **Seaborn** â†’ visualization  
- **Scikit-Learn** â†’ regression, preprocessing, evaluation  
- **SciPy** â†’ skewness correction  

---

## ğŸ§© Data Preprocessing Pipeline

1. Handle missing values  
2. Encode categorical variables (One-Hot Encoding)  
3. Map ordinal quality features (`Ex`, `Gd`, `TA`, etc.)  
4. Correct skewed numeric features using `log1p`  
5. Scale features using `StandardScaler`  
6. Train & evaluate regression models  

---

## ğŸ“Š Model Results

| Model | RÂ² | Cross-Validation | RMSE | MAE |
|-------|----|------------------|------|-----|
| **Linear Regression** | 0.766 | **0.72** | 42,391 | **22,173** |
| **Polynomial Regression (deg=2)** | **0.786** | 0.67 | **40,523** | 28,044 |

### ğŸ§  Insights
- Polynomial Regression fit training data slightly better  
- However, Linear Regression generalized better on unseen data  
- Skew correction & feature engineering improved both models significantly  

---

## ğŸš€ Next Steps

- Add **Decision Tree**, **Random Forest**, and **XGBoost** regressors  
- Try **log(SalePrice)** target transformation  
- Transition to **Deep Learning** (Neural Networks for regression)

---

## ğŸ§¾ Repository Structure

House-Prices-Regression/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ test.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ linear_regression.ipynb
â”‚ â””â”€â”€ polynomial_regression.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

---

## ğŸ§© How to Run

```bash
git clone https://github.com/<yourusername>/House-Prices-Regression.git
cd House-Prices-Regression
pip install -r requirements.txt
jupyter notebook notebooks/linear_polynomial_regression.ipynb
```

---

ğŸ“Š Dataset

Available on Kaggle: https://www.kaggle.com/c/house-prices-advanced-regression-techniques

---

ğŸ‘¨â€ğŸ’» Author

**Rami Bahi**

ğŸ“ Masterâ€™s Student in Artificial Intelligence

ğŸ’» Passionate about Machine Learning, Deep Learning & Web Development

---

â­ If you like this project

Give it a star â­ on GitHub to support my work and journey!
